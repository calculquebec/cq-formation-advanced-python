{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Finding Bottlenecks\n",
    "---\n",
    "\n",
    "Now that we have learned some techniques with no to minor code modifications, we might want to tweak our actual code itself since there are chances we can do better. The way to determine what part of our code needs attention is called profiling. Profilers come in a variety of shapes and functionalities but what we'll use are two deterministic/event-based profilers as opposed to statistical profilers. This means that instead of relying on partial data by sampling at regular intervals, hit count will be exact and can be reproduced. The downside to using an event-based profiler is that is can slow down your code, sometimes significantly.\n",
    "\n",
    "Here are some things to keep in mind before optimizing:\n",
    "\n",
    "* Make sure your code works/is correct beforehand.\n",
    "* Make sure you focus on the right code by profiling.\n",
    "* Make and keep performance measurements along the way.\n",
    "* Make the smallest changes possible at a time.\n",
    "* Keep track of your code changes using Git.\n",
    "* Always make sure your unit tests/your output is still valid.\n",
    "\n",
    "We'll start with a simple example that can also be found in the profile.py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "def gen_data(n):\n",
    "    numbers = []\n",
    "    for i in range(n):\n",
    "        numbers.append(random.random())\n",
    "    return numbers\n",
    "\n",
    "def sum_nexts(numbers):\n",
    "    sums = []\n",
    "    for i in range(len(numbers)):\n",
    "        for j in range(i+1, len(numbers)):\n",
    "            if len(sums) < i+1:\n",
    "                sums.append(0.)\n",
    "            sums[i] = sums[i] + numbers[j]\n",
    "    return sums\n",
    "\n",
    "def profile_sum(n):\n",
    "    numbers = gen_data(n)\n",
    "    sums = sum_nexts(numbers)\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small program takes a number n as input, generates n random elements in a list called numbers, and compute a list of n elements called sums, such as:\n",
    "\n",
    "$$ {\\Large \\mathrm{sum}_i = \\sum_{a=i+1}^{n-1} \\mathrm{number}_a } $$\n",
    "\n",
    "The first thing we want to do is make note of the time it takes to run the program. We'll start small, with a run of 10000 generated elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to make our first profiling measurement to find our (possible) bottlenecks. For that, we'll use the recommended Python profiler: [cProfile](https://docs.python.org/2/library/profile.html#module-cProfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?%prun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must remember that you can't compare run timings from profiled and non-profiled code. Profiling incurs an overhead and will usually be a lot slower (about 50% here). The default output is not useful as entries are in no particular order. What we want most of the time is function calls sorted by their reverse cumulative time. This can be accomplished by the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun -s cumulative profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then possible to infer that most of the computation time, as expected, is taking place in the sum_nexts function. Beware that it might not always be so predictable and that you must profile before starting optimizing your code.\n",
    "\n",
    "To save the output in a variable we can use -q to suppress screen output and -r to return the stats output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = %prun -q -r profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is almost always what you want when profiling a real software as there will be a lot of functions to display.\n",
    "\n",
    "The problem when using cProfile is that it's view is very low-level. We know where to start looking, but we don't know the details of the function execution. To dig further, we need to use a line-based profiler called line_profiler, provided by the %lprun IPython magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_nexts(numbers):\n",
    "    sums = []\n",
    "    for i in range(len(numbers)):\n",
    "        for j in range(i+1, len(numbers)):\n",
    "            if len(sums) < i+1:\n",
    "                sums.append(0.)\n",
    "            sums[i] = sums[i] + numbers[j]\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load, get help on, start the profiler and run our program using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?%lprun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%lprun -f sum_nexts profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes it clear that a lot of the time is consumed by the (innocuously looking) if len(sums) < i+1 statement. It is not slow per say, but called 50 million times, it becomes significant. A simple change we can make is to initialize our result list before with zeros. This change would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_nexts(numbers):\n",
    "    sums = [0.]*len(numbers)\n",
    "    for i in range(len(numbers)):\n",
    "        for j in range(i+1, len(numbers)):\n",
    "            sums[i] = sums[i] + numbers[j]\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to measure the impact of our change, by comparing to the original run time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a 50% gain just doing this small modification. Let's see if we can do better. We run the line-level profiler again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%lprun -f sum_nexts profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That inner loop (j variable) sure seems to be a problem. Instead of iterating from i+1 to len(number)-1, we could use Python splicing to see if we get better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_nexts(numbers):\n",
    "    sums = [0.]*len(numbers)\n",
    "    for i in range(len(numbers)):\n",
    "        sums[i] = sum(numbers[i+1:])\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's great! A 20x improvement since the beginning of the process. Let's see what our line-based profiler has to say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%lprun -f sum_nexts profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we want to see: almost all run time is the actual computation (sum), which is great. But still, since we are working with lists, why not use Numpy arrays and see what we can achieve? Here is a modified version using Numpy arrays instead is lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "\n",
    "numpy.random.seed(int(time.time()))\n",
    "\n",
    "def gen_data(n):\n",
    "    return numpy.random.random(n)\n",
    "\n",
    "def sum_nexts(numbers):\n",
    "    sums = numpy.zeros(len(numbers))\n",
    "    for i in range(len(numbers)):\n",
    "        sums[i] = sum(numbers[i+1:])\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But running it yields an unexpected result. We are far worse than we were before those modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? Let's ask our profiler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%lprun -f sum_nexts profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is again expected, we spend all of our time doing the sum. But why is it slower? The answer is that we are still using the Python built-in sum function and not it's Numpy counterpart. That means the code goes back and forth between Python and C (Numpy). We can make the code execute longer in the Numpy library by using its own sum function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_nexts(numbers):\n",
    "    sums = numpy.zeros(len(numbers))\n",
    "    for i in range(len(numbers)):\n",
    "        sums[i] = numbers[i+1:].sum()\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit profile_sum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the end, we could get about 65 times faster in a really short amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## More Data Processing {.challenge}\n",
    ">\n",
    "> Try optimizing the below code by first using a profiler and finding hotspots.\n",
    ">\n",
    "> __Tip__: Before running the script, generate a random sample.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1234)\n",
    "with open(\"inputs.dat\", \"w\") as fp:\n",
    "    for _ in range(5000):\n",
    "        for _ in range(5000):\n",
    "            fp.write(\"{0},\".format(random.random()))\n",
    "        fp.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load cq-formation-advanced-python/exercices/process_data.py\n",
    "from __future__ import division\n",
    "\n",
    "def read_data():\n",
    "    data = []\n",
    "    fp = open(\"inputs.dat\", \"r\")\n",
    "\n",
    "    line = 1\n",
    "    while line:\n",
    "        line = fp.readline()\n",
    "        if line:\n",
    "            row = []\n",
    "            for elem in line.split(','):\n",
    "                elem = elem.strip()\n",
    "                if elem:\n",
    "                    row.append(float(elem))\n",
    "            data.append(row)\n",
    "        \n",
    "    fp.close()\n",
    "    return data\n",
    "\n",
    "def process_A(data):\n",
    "    \"\"\"\n",
    "    Return a new matrix of the same shape as data, with each original\n",
    "    element squared by it's transposition equivalent.\n",
    "\n",
    "    result[i][j] = data[i][j] ** data[j][i]\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in range(len(data)):\n",
    "        row = []\n",
    "        for j in range(len(data[i])):\n",
    "            row.append(data[i][j] ** data[j][i])\n",
    "        result.append(row)\n",
    "    return result\n",
    "\n",
    "def process_B(m1, m2):\n",
    "    \"\"\"\n",
    "    Return the sum of the difference between each corresponding\n",
    "    elements of two square matrices.\n",
    "\n",
    "    diff = (m2[0][0] - m1[0][0]) + (m2[0][1] - m1[0][1]) + ...\n",
    "    \"\"\"\n",
    "\n",
    "    diff = 0.\n",
    "    for i in range(len(m1)):\n",
    "        for j in range(len(m1[i])):\n",
    "            diff += m2[i][j] - m1[i][j]\n",
    "    return diff\n",
    "\n",
    "def main():\n",
    "    data = read_data()\n",
    "    result_1 = process_A(data)\n",
    "    print(\"Difference is: %s\"%process_B(data, result_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A possible solution can be found in the solutions/process_data.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-Workshop",
   "language": "python",
   "name": "python-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
